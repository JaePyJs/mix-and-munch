# Quick Start Guide - Mix & Munch

## ğŸš€ 5-Minute Setup

```bash
# 1. Install
npm install

# 2. Configure
echo 'GEMINI_API_KEY=your_key_here' > .env.local
echo 'GLM_API_KEY=your_fallback_key' >> .env.local

# 3. Run
npm run dev

# 4. Open http://localhost:3000
```

---

## ğŸ“± Key Features to Test

### Try These Inputs:
1. **"Just garlic and onions"** - Watch AI create magic
2. **"Eggs, rice, and soy sauce"** - Filipino fried rice incoming
3. **"Chicken, tomato, vinegar"** - Adobo variations
4. **"2 ingredients surprise"** - Let Mix get creative

---

## ğŸ¯ What to Look For

âœ… **Recipe Cards Should Show**:
- ğŸ“‹ Recipe Title (in lime green)
- â±ï¸ Time & Servings
- ğŸ¥˜ Ingredients with measurements
- ğŸ‘¨â€ğŸ³ Step-by-step instructions
- ğŸ’¡ Pro tip/technique
- ğŸ‡µğŸ‡­ Cultural insight
- âœ¨ Plating suggestion

âœ… **AI Model Badge** shows which responded:
- ğŸ§  "Gemini 2.5 Pro" (primary)
- âš¡ "Gemini 2.5 Flash" (if enabled)
- ğŸ”„ "GLM 4.6 (Fallback)" (if Gemini failed)

---

## ğŸ“± Mobile Test Checklist

- [ ] Open on iPhone/Android
- [ ] Header collapses to dropdown âœ“
- [ ] Recipe card doesn't overflow âœ“
- [ ] Buttons are tappable âœ“
- [ ] Text is readable (not tiny) âœ“

---

## ğŸ”§ Configuration Options

```env
# Use Gemini 2.5 Pro (recommended)
GEMINI_API_KEY=sk-xxx-your-key-xxx

# Optional: GLM 4.6 fallback
GLM_API_KEY=sk-xxx-glm-key-xxx

# Optional: Use faster Flash model (less capable)
USE_GEMINI_FLASH=true  # Default: false
```

---

## ğŸ§ª Test the Fallback

1. Set `GEMINI_API_KEY=invalid_key`
2. Keep `GLM_API_KEY=your_real_key`
3. Send message
4. Watch it fail over to GLM 4.6 âœ“

---

## ğŸ“Š File Structure

```
app/
  api/chat/route.ts          â† AI integration (Gemini + GLM)
  chat/page.tsx              â† Chat interface
  profile/page.tsx           â† User profile

components/
  chat/
    RecipeCard.tsx           â† Beautiful recipe display
    AIModelBadge.tsx         â† Shows which AI responded
    MessageBubble.tsx        â† Chat messages
```

---

## ğŸš€ Production Deploy

```bash
# Build for production
npm run build

# Test production build
npm run start

# Deploy to Vercel
npm install -g vercel
vercel
```

---

## ğŸ’¡ Pro Tips

- **Streaming**: Responses appear word-by-word, not all at once
- **Context**: AI remembers messages in this chat session
- **Fallback**: Happens automatically, no user action needed
- **Mobile**: Test with actual phone, not just DevTools

---

## ğŸ†˜ Quick Troubleshoot

| Issue | Solution |
|-------|----------|
| "No AI providers configured" | Add GEMINI_API_KEY to .env.local |
| Recipes don't show sections | Check API response, maybe rate limited |
| Mobile layout broken | Clear browser cache, refresh |
| Super slow responses | Check internet, verify API quotas |

---

## ğŸ“ Key People

**Developer**: Jose Miguel Barron  
**Project**: Mix & Munch - Capstone  
**Status**: âœ… Production Ready

---

**Next Step**: Set your API keys and run `npm run dev` ğŸ›
